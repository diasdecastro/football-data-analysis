{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347942db",
   "metadata": {},
   "source": [
    "# Experiments with logistic regression model for expected goals (xG) prediction.\n",
    "\n",
    "**Note:**\n",
    "- Use this file to improve the model, try different features, regularization techniques, etc.\n",
    "- This file is only for experimentation, do not log to MLflow.\n",
    "- Implement important changes in the main training script src/tasks/xg/train/train_xg.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "# Add project root to Python path\n",
    "root = Path(os.getcwd()).parents[3]\n",
    "sys.path.insert(1, str(root))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from src.common import io\n",
    "from src.tasks.xg.features.pipeline import build_feature_pipeline\n",
    "from src.tasks.xg.train.train_xg import evaluate_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c4c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the data\n",
    "\n",
    "df = io.read_table(Path(root) / \"data/gold/xg_features.parquet\")\n",
    "included_features = [\n",
    "    \"end_x\",\n",
    "    \"end_y\",\n",
    "    \"shot_distance\",\n",
    "    \"shot_angle\",\n",
    "    \"body_part_right_foot\",\n",
    "    \"body_part_left_foot\",\n",
    "    \"body_part_head\",\n",
    "    \"body_part_other\",\n",
    "    \"is_open_play\",\n",
    "    \"one_on_one\",\n",
    "]\n",
    "\n",
    "pipeline = build_feature_pipeline()\n",
    "X = pipeline.transform(df)[included_features].dropna()\n",
    "y = df[\"is_goal\"].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fbf0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering. This step happens inside `prepare_features` on the main workflow.\n",
    "\n",
    "X[\"log_angle\"] = np.log(X[\"shot_angle\"] + 1e-5)\n",
    "X[\"one_on_one_x_log_angle\"] = X[\"one_on_one\"].astype(int) * X[\"shot_angle\"]\n",
    "X[\"one_on_one_x_dist\"] = X[\"one_on_one\"].astype(int) * X[\"shot_distance\"]\n",
    "\n",
    "X[\"head_x_dist\"] = X[\"body_part_head\"].astype(int) * X[\"shot_distance\"]\n",
    "X[\"distance_x_angle\"] = X[\"shot_distance\"] * X[\"log_angle\"]\n",
    "\n",
    "print(f\"Goal/nongoal ratio: {y.value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec5b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_continous = X[[\"end_x\", \"end_y\", \"shot_distance\", \"shot_angle\", \"log_angle\", \"one_on_one_x_log_angle\", \"one_on_one_x_dist\", \"head_x_dist\", \"distance_x_angle\"]]\n",
    "X_scaled = scaler.fit_transform(X_continous)\n",
    "\n",
    "X.drop([\"end_x\", \"end_y\", \"shot_distance\", \"shot_angle\", \"log_angle\", \"one_on_one_x_log_angle\", \"one_on_one_x_dist\", \"head_x_dist\", \"distance_x_angle\"], axis=1, inplace=True)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=[\"end_x\", \"end_y\", \"shot_distance\", \"shot_angle\", \"log_angle\", \"one_on_one_x_log_angle\", \"one_on_one_x_dist\", \"head_x_dist\", \"distance_x_angle\"], index=X.index)\n",
    "X = pd.concat([X, X_scaled_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1759b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated model training\n",
    "def train_model(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000, solver=\"lbfgs\", penalty=\"l2\", C=0.3)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='neg_log_loss')\n",
    "    print(f\"Cross-validated Log Loss scores: {-cv_scores}\")\n",
    "    print(f\"Mean CV Log Loss: {-cv_scores.mean()}\")\n",
    "\n",
    "    # Fit the model on the entire training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "\n",
    "    return model, X_train, X_test, y_train, y_test\n",
    "  \n",
    "model, X_train, X_test, y_train, y_test = train_model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab19429",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f14ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "\n",
    "y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "metrics = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "for dataset in [\"train\", \"test\"]:\n",
    "    print(f\"{dataset.capitalize()} Performance:\")\n",
    "    print(f\"  ROC-AUC: {metrics[dataset]['roc_auc']:.3f}\")\n",
    "    print(f\"  Brier Score: {metrics[dataset]['brier_score']:.3f}\")\n",
    "    print(f\"  Log Loss: {metrics[dataset]['log_loss']:.3f}\")\n",
    "    print(classification_report(y_test if dataset == \"test\" else y_train, y_test_pred if dataset == \"test\" else y_train_pred))\n",
    "    print()\n",
    "\n",
    "# Calibration curve\n",
    "calib_curve_train = metrics[\"train\"][\"calibration_curve\"]\n",
    "calib_curve_test = metrics[\"test\"][\"calibration_curve\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(calib_curve_train[0], calib_curve_train[1], marker='o', label='Train')\n",
    "plt.plot(calib_curve_test[0], calib_curve_test[1], marker='o', label='Test')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Observed Probability')\n",
    "plt.title('Calibration Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
